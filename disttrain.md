#### 1 ParamServer



#### 2 Pathways

简单的 BSP 模型在新的深度学习任务上会有问题：

- 模型越来越大，会导致整个模型在一个加速器上放不下，因此纯粹用数据并行可能不行，需要用一个 pipeline 并行的方式来进行任务的切割；
- 现在模型在探索稀疏性，即整个模型不是全连接，而是一个系数连接的过程，导致在通讯上和任务调度上会不一样，因此 MPI 的通信会变差；

机器学习的集群变得越来越异构，也即有一些岛，这些岛是同构的加速器高速互联，但岛与岛之间的联系就不那么紧密。一台机器可以认为是一个岛，里面有多块 GPU，GPU 之间的互联就很快；但跨到不同机器时网络带宽便不那么高。因为这种异构性的存在，可能去追求多程序多数据的执行，这样在调度和优化的时候会略有不同。

现在的基础模型，训练和推理可能同时进行，因为做多模态时一个模型会被读个任务同时使用，这样可以提升硬件的使用率。

```python
def get_devices(n):
    """ Allocates `n` virtual TPU devices on an island. """
    device_set = pw.make
```

##### resources manager





#### GPipe

CPU 中的流水线指，如果一条指令需要多个时钟周期执行，且每个时钟周期用到硬件不同，可以考虑将多条指令排队流水进行执行，这样每个硬件在任何时刻都在做计算，这样可以提升 CPU 效率。这里把同样的思想用来优化在多个 GPU 上进行模型训练。

对任何网络，只要能表示成一些层串联而成，都可以使用 GPipe。把层的不同子序列放在多个加速器上进行执行，这样既有灵活性又有高效性。

内存容量和通信带宽的硬件限制。一种模型并行。

GPipe 里主要用到了两个技术，

- 一个是 re-materialization，就是将一些中间结果丢掉，下次使用的时候再重新计算，这样能减少一些内存的占有率；
- 另一个是 micro-batches，就是将小批量再进行切分，做到更小的有一个尺度。

GPipe 是在一个被称为 Lingvo 的框架上实现，lingvo 是基于 tensorflow 的一个框架，特别针对变长输入的语言模型。这个框架的一个特点是追求可重复性，具体的做法是将所有的超参数、数据集全部写在代码中，因此对这个框架而言，不管是一个层、一个网络、一个训练任务、还是一个数据集，都基于一个同样的基类，这个基类本质上就是一个字典，而且可以认为整个任务就是一个巨大的字典。

神经网络可以定义成 $L$ 层的序列，第 $i$ 层本质上就是一个前向函数 $f_i$ 和以及对应的可学习参数 $w_i$。GPipe 允许用户指定这一层的开销 $c_i$，在定义好任务后可以指定将网络切成的块数 $K$，这样网格网络就被分为 $K$ 个子序列，每个子序列被称为一个单元。

在计算的时候，将第 $k$ 个单元 $p_k$ 放在第 $k$ 个加速器上，